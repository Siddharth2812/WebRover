{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "def set_env_vars(var):\n",
    "    os.environ[var] = os.getenv(var)\n",
    "\n",
    "\n",
    "vars = [\"OPENAI_API_KEY\", \"LANGCHAIN_API_KEY\", \"LANGCHAIN_TRACING_V2\", \"LANGCHAIN_ENDPOINT\", \"LANGCHAIN_PROJECT\", \"TAVILY_API_KEY\"]\n",
    "\n",
    "for var in vars:\n",
    "    set_env_vars(var)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from playwright.async_api import Page\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class Bbox(TypedDict):\n",
    "    x: int\n",
    "    y: int\n",
    "    text: str\n",
    "    type: str\n",
    "    ariaLabel: str\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    page: Page\n",
    "    image: str\n",
    "    bboxes: List[Bbox]\n",
    "    updated_notes: List[BaseMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScreenShot and Annotation Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "from playwright.async_api import Page\n",
    "\n",
    "\n",
    "with open(\"mark_page.js\") as f:\n",
    "    mark_page_script = f.read()\n",
    "\n",
    "async def is_image_blank(image_bytes: bytes) -> bool:\n",
    "    \"\"\"Return True if the screenshot is fully blank (e.g. all white), else False.\"\"\"\n",
    "    if not image_bytes:\n",
    "        return True\n",
    "    img = PILImage.open(io.BytesIO(image_bytes)).convert(\"L\")\n",
    "    # If getbbox() returns None, the image is entirely one color\n",
    "    return img.getbbox() is None\n",
    "\n",
    "async def capture_screenshot(page: Page, max_retries=3, wait_seconds=2) -> bytes:\n",
    "    \"\"\"Take a screenshot, retry if blank (completely white).\"\"\"\n",
    "    screenshot_bytes = b\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        # Wait for the page to be fully loaded\n",
    "        await page.wait_for_load_state(\"networkidle\")\n",
    "        \n",
    "        # Take screenshot\n",
    "        screenshot_bytes = await page.screenshot(path=\"screenshot.png\")\n",
    "        \n",
    "        # Check if it's blank\n",
    "        if not await is_image_blank(screenshot_bytes):\n",
    "            return screenshot_bytes\n",
    "        \n",
    "        # If blank, wait a bit and retry\n",
    "        print(f\"[capture_screenshot] Screenshot is blank (attempt {attempt+1}/{max_retries}). Retrying...\")\n",
    "        await asyncio.sleep(wait_seconds)\n",
    "    \n",
    "    # If we get here, all attempts yielded a blank screenshot\n",
    "    print(\"[capture_screenshot] All screenshot attempts were blank.\")\n",
    "    return screenshot_bytes  # Return whatever we got last\n",
    "\n",
    "\n",
    "async def mark_page(page):\n",
    "\n",
    "    \"\"\"\n",
    "    1. Wait for the page to be loaded using 'networkidle'.\n",
    "    2. Attempt to run a 'mark_page_script' that presumably marks and returns bounding boxes.\n",
    "    3. Retry up to 10 times if it fails.\n",
    "    4. Capture a screenshot with retry logic (up to 3 tries) if the page is blank.\n",
    "    5. Process screenshot (grayscale, resize, quantize, compress).\n",
    "    6. Remove the markings before returning.\n",
    "    \"\"\"\n",
    "\n",
    "    bboxes = []\n",
    "\n",
    "    for attempt in range (3):\n",
    "        try: \n",
    "            await page.wait_for_load_state(\"networkidle\")\n",
    "\n",
    "            await page.evaluate(mark_page_script)\n",
    "            bboxes = await page.evaluate(\"markPage()\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"[mark_page] Attempt {attempt+1}/3 failed to mark page: {e}\")\n",
    "            await asyncio.sleep(3)\n",
    "    # Get screenshot as bytes\n",
    "    await page.wait_for_load_state(\"networkidle\")\n",
    "    screenshot_bytes = await capture_screenshot(page, max_retries=3)\n",
    "    \n",
    "    # Process screenshot if we have any bytes\n",
    "    if screenshot_bytes:\n",
    "        img = PILImage.open(io.BytesIO(screenshot_bytes))\n",
    "        # Convert to grayscale\n",
    "        img = img.convert('L')\n",
    "        # Resize\n",
    "        max_size = (300, 300)\n",
    "        img.thumbnail(max_size, PILImage.Resampling.LANCZOS)\n",
    "        # Quantize and convert back to grayscale\n",
    "        img = img.quantize(colors=16).convert('L')\n",
    "        \n",
    "        # Compress\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(\n",
    "            buffer,\n",
    "            format='JPEG',\n",
    "            quality=5,      # Low quality -> smaller size\n",
    "            optimize=True,\n",
    "            progressive=True\n",
    "        )\n",
    "        compressed_bytes = buffer.getvalue()\n",
    "    else:\n",
    "        # If screenshot is empty or never taken, handle gracefully\n",
    "        print(\"[mark_page] Using empty screenshot due to failure or blank screenshot.\")\n",
    "        compressed_bytes = b\"\"\n",
    "\n",
    "    await page.wait_for_load_state(\"networkidle\")\n",
    "    try:\n",
    "        await page.evaluate(\"unmarkPage()\")\n",
    "    except Exception as e:\n",
    "        print(f\"[mark_page] Could not unmark page: {e}\")\n",
    "\n",
    "    # Build final result\n",
    "    return {\n",
    "        \"image\": base64.b64encode(compressed_bytes).decode(\"utf-8\"),\n",
    "        \"bboxes\": bboxes\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Browser setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup_browser(go_to_page: str):\n",
    "    playwright = await async_playwright().start()\n",
    "    browser = await playwright.chromium.launch(headless=False)\n",
    "    page = await browser.new_page()\n",
    "    try:\n",
    "        # Increase timeout to 80 seconds and add wait_until option\n",
    "        await page.goto(go_to_page, timeout=80000, wait_until=\"domcontentloaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading page: {e}\")\n",
    "        # Fallback to Google if the original page fails to load\n",
    "        await page.goto(\"https://www.google.com\", timeout=60000, wait_until=\"domcontentloaded\")\n",
    "    return playwright, browser, page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def annotate_page(state: AgentState):\n",
    "    page = state[\"page\"]\n",
    "    result = await mark_page(page)\n",
    "    print(\"***************ANNOTATE_PAGE***************\\n\")\n",
    "    print(result)\n",
    "    print(\"***************ANNOTATE_PAGE_DONE***************\\n\")\n",
    "    return {**state, **result}\n",
    "\n",
    "#initial_state = AgentState(page=page, bboxes=[])\n",
    "#state = await annotate_page(initial_state)\n",
    "#state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "async def prompt_definition():   \n",
    "\n",
    "    print(\"***************PROMPT_DEFINITION***************\\n\")\n",
    "    template = \"\"\"You are a web-browsing robot. You see a webpage with various labeled bounding boxes. \n",
    "    Each bounding box has a **Numerical Label** in the top-left corner, which identifies an interactive element. \n",
    "\n",
    "    Your goal is to handle the **User's Input** by analyzing the webpage's bounding boxes and deciding on **one** of the \n",
    "    following Actions to perform **per iteration**:\n",
    "\n",
    "    1. Click a Web Element.\n",
    "    2. Delete existing content in a textbox and then type content.\n",
    "    3. Scroll up or down.\n",
    "    4. Wait \n",
    "    5. Go back\n",
    "    7. Return to google to start over.\n",
    "    8. Respond with the final answer\n",
    "\n",
    "    **Important Guidelines**:\n",
    "    1. **Close popups** if they appear by clicking on the bounding box for the \"close\" button.  \n",
    "    2. If the User wants to search something (like \"NVIDIA Stock forecast\"), you should **Type** the query into the Google \n",
    "    search bar bounding box.  \n",
    "    3. Do **not** use \"Bing\" unless explicitly instructed.  \n",
    "    4. If you must produce a final answer (e.g., if the user says \"Please give me the final answer now\"), use \n",
    "    **ANSWER; [content]**.  \n",
    "    5. Properly define the concise search query or terms you need to type in search bar or any input field.\n",
    "\n",
    "    **Action Format** must be exactly one of:\n",
    "    - `Click [Numerical_Label]`\n",
    "    - `Type [Numerical_Label]; [Content]`\n",
    "    - `Scroll [Numerical_Label or WINDOW]; [up or down]`\n",
    "    - `Wait`\n",
    "    - `GoBack`\n",
    "    - `ANSWER; [content]`\n",
    "\n",
    "    ### Example\n",
    "\n",
    "    If the user says \"NVIDIA Stock forecast,\" and the bounding box for the Google search bar is labeled 2, you might respond:\n",
    "\n",
    "    Thought: The user wants me to search for NVIDIA Stock forecast in Google. Action: Type [2]; NVIDIA Stock forecast\n",
    "\n",
    "\n",
    "    -----\n",
    "\n",
    "    **Now, here is the format of your output to the user**:\n",
    "    1. Thought: a short text describing your reasoning about the next action.\\\\n\n",
    "    2. Action: the single action you decide to take, in one of the required formats above.\n",
    "\n",
    "    -----\n",
    "\n",
    "    Observation (the screenshot, bounding boxes, etc.): {{result}}\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate(\n",
    "        messages=[\n",
    "            (\"system\", template),\n",
    "            (\"placeholder\", \"{updated_notes}\"),\n",
    "            (\"human\", \"Image: {image}\"),\n",
    "            (\"human\", \"Bounding Boxes: {bboxes}\"),\n",
    "            (\"human\", \"Input: {input}\")\n",
    "        ],\n",
    "        input_variables=[\"image\", \"bboxes\", \"input\"],\n",
    "        partial_variables={\"updated_notes\": []},\n",
    "        optional_variables=[\"updated_notes\"]\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "    #updated_notes = [\"Some notes\"]\n",
    "    #image = state[\"image\"]\n",
    "    #bbox_descriptions = state[\"bbox_descriptions\"]\n",
    "    #input = \"NVIDIA Stock forecast\"\n",
    "    #bboxes = state[\"bboxes\"]\n",
    "\n",
    "    #prompt_value = prompt.invoke({\"updated_notes\": updated_notes, \"image\": image, \"bboxes\": bboxes, \"input\": input})\n",
    "    #print(prompt_value)\n",
    "    #print(\"***************PROMPT_DEFINITION_DONE***************\\n\")\n",
    "    #return prompt_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def llm_response(prompt_value):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens =4096, temperature=0)\n",
    "\n",
    "    llm_chain = prompt_value | llm\n",
    "\n",
    "    response = llm_chain.invoke({\"updated_notes\": updated_notes, \"image\": image, \"bboxes\": bboxes, \"input\": input})\n",
    "    print(\"***************LLM_RESPONSE***************\\n\")\n",
    "    print(response)\n",
    "    print(\"***************LLM_RESPONSE_DONE***************\\n\")\n",
    "    return response.content\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens =4096, temperature=0)\n",
    "\n",
    "#updated_notes = [\"Some notes\"]\n",
    "#image = state[\"image\"]\n",
    "#bboxes = state[\"bboxes\"]\n",
    "#input = \"Look for the actual Attention is all you need paper and write a concise summary on it\"\n",
    "\n",
    "#response = await llm_response(prompt_value)\n",
    "#response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_action(text: str) -> dict:\n",
    "    action_prefix = \"Action: \"\n",
    "    text = text.content\n",
    "    if not text.strip().split(\"Action:\")[-1]:\n",
    "        return {\"action\": \"retry\", \"args\": f\"Could not parse LLM Output: {text}\"}\n",
    "    action_block = text.strip().split(\"Action: \")[-1]\n",
    "    split_output = action_block.split(\"; \", 1)\n",
    "    if len(split_output) == 1:\n",
    "        action, args = split_output[0], None\n",
    "    else:\n",
    "        action, args = split_output\n",
    "    return {\"action\": action, \"args\": args}\n",
    "\n",
    "#predicted_action = await parse_action(response)\n",
    "#predicted_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************PROMPT_DEFINITION***************\n",
      "\n",
      "***************ANNOTATE_PAGE***************\n",
      "\n",
      "{'image': '/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAKBueIx4ZKCMgoy0qqC+8P//8Nzc8P//////////////////////////////////////////////////////////wgALCACpASwBAREA/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEC/9oACAEBAAAAAdJoAAABCsLoAAAAAJLQAAAAAAAASgAAAAAgEtAAAABAi0AAAAAJQAAAAAAhQAAAAAAAAACAUAAAABCoUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLKlASgAM6gqABSAFAgFEqUlAAAllka/8QAFhAAAwAAAAAAAAAAAAAAAAAAEWCQ/9oACAEBAAEFAkkT7//EABQQAQAAAAAAAAAAAAAAAAAAAJD/2gAIAQEABj8CUT//xAAhEAACAQMFAAMAAAAAAAAAAAABEQAQIVAgMDFAQWBhgP/aAAgBAQABPyE09fbOk8xmA4Qh0ALLvCnieRiOjjo+/cUvxUxQYRYz34AbwVMFvzSdQey775boaH6g6SzJ0f/aAAgBAQAAABDgAAADMAAAAAAAAAAAAAAAQAAAAAM2AAAAALgAAAAAgAAAAAA4AAAAAAAAAA/gAAAAHOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0AAAAlN/iAAPoSIAACm//xAAlEAADAAEEAgIDAAMAAAAAAAAAAREhEDFRYUBBIDBQcYGAobH/2gAIAQEAAT8QWreCfZJmE75S2ZgnRNL2biY0x3O3/g9uPWE8uEJrVdj9yq7/AJdot2J3b42+e0ZiSVCpjBtswXgwVZWKtxOJ+3WKnHh+c1VBbEpG63xDZh/RKbDVT9DNyqZQ2/2z9IvLbn0NVRiRP38G55LV+1qyi3ZXh5VhdaX4+9P55SYISKVF7Re0JVBIlL2i9r8BOkTpE6Wk6J0idE/xArEFZko9cmSlKX4zhPv9DYvRWILbJbmRUV3Lp7I+SPnSPkV9sziMzyR8mefi9sG6xEZGRkZGRkf0cmeT2iPk9kfJmO/QtvK96blo9tP/2Q==', 'bboxes': [{'id': 0, 'x': 44.29296875, 'y': 30, 'type': 'a', 'text': 'About', 'ariaLabel': ''}, {'id': 1, 'x': 99.3203125, 'y': 30, 'type': 'a', 'text': 'Store', 'ariaLabel': ''}, {'id': 2, 'x': 1025.390625, 'y': 30, 'type': 'a', 'text': 'Gmail', 'ariaLabel': 'Gmail '}, {'id': 3, 'x': 1078.68359375, 'y': 30, 'type': 'a', 'text': 'Images', 'ariaLabel': 'Search for Images '}, {'id': 4, 'x': 1135, 'y': 30.1328125, 'type': 'a', 'text': '', 'ariaLabel': 'Google apps'}, {'id': 5, 'x': 1211.5, 'y': 30, 'type': 'a', 'text': 'Sign in', 'ariaLabel': 'Sign in'}, {'id': 6, 'x': 617.5, 'y': 270, 'type': 'textarea', 'text': '', 'ariaLabel': 'Search'}, {'id': 7, 'x': 841, 'y': 269, 'type': 'div', 'text': '', 'ariaLabel': ''}, {'id': 8, 'x': 863, 'y': 265.5, 'type': 'path', 'text': '', 'ariaLabel': ''}, {'id': 9, 'x': 903.0087280273438, 'y': 270, 'type': 'circle', 'text': '', 'ariaLabel': ''}, {'id': 10, 'x': 562.80078125, 'y': 341, 'type': 'input', 'text': '', 'ariaLabel': 'Google Search'}, {'id': 11, 'x': 709.640625, 'y': 341, 'type': 'input', 'text': '', 'ariaLabel': \"I'm Feeling Lucky\"}, {'id': 12, 'x': 69.62890625, 'y': 696.25, 'type': 'a', 'text': 'Advertising', 'ariaLabel': ''}, {'id': 13, 'x': 162.6640625, 'y': 696.25, 'type': 'a', 'text': 'Business', 'ariaLabel': ''}, {'id': 14, 'x': 279.421875, 'y': 696.25, 'type': 'a', 'text': 'How Search works', 'ariaLabel': ''}, {'id': 15, 'x': 508.2109375, 'y': 694.5, 'type': 'img', 'text': '', 'ariaLabel': ''}, {'id': 16, 'x': 649.125, 'y': 695.25, 'type': 'span', 'text': 'Our third decade of climate action: join us', 'ariaLabel': ''}, {'id': 17, 'x': 1073.34765625, 'y': 696.25, 'type': 'a', 'text': 'Privacy', 'ariaLabel': ''}, {'id': 18, 'x': 1145.35546875, 'y': 696.25, 'type': 'a', 'text': 'Terms', 'ariaLabel': ''}, {'id': 19, 'x': 1219.70703125, 'y': 695.5, 'type': 'div', 'text': 'Settings', 'ariaLabel': ''}]}\n",
      "***************ANNOTATE_PAGE_DONE***************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Look for the actual Attention is all you need paper and write a concise summary on it',\n",
       " 'page': <Page url='https://www.google.com/'>,\n",
       " 'pred': {'action': 'Type [6]', 'args': 'Attention is all you need paper'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "result = await setup_browser(\"https://www.google.com\")\n",
    "playwright, browser, page = result\n",
    "prompt_value = await prompt_definition()\n",
    "\n",
    "prediction =  RunnablePassthrough.assign(\n",
    "    pred = annotate_page | prompt_value | llm | parse_action\n",
    ")\n",
    "\n",
    "result = await prediction.ainvoke({\"input\": \"Look for the actual Attention is all you need paper and write a concise summary on it\", \"page\": page})\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "1. Click (at labelled box)\n",
    "2. Type\n",
    "3. Scroll\n",
    "4. Wait\n",
    "5. Go back\n",
    "6. Go to search engine (Google)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
